---
layout: nb-post
title: "A Method for Stability Testing of Unsupervised Methods v4"
author:
github:
tags: 
---

<!--put these separators somewhere appropriate:-->
<!--excerpt.start-->
<!--excerpt.end--><!--more-->

<!--you can set this to false if you want code displayed by default-->
<script>
hide_code=true;
</script>

<!--this is just hacky filler-->
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>
<hr>
</p>
</div>
</div>
</div>
<!--back to the good stuff-->

<div tabindex="-1" id="notebook" class="border-box-sizing">
<div class="container" id="notebook-container">

<!--if you've decided to show code by default, please reword the following-->
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>
NOTE: the code in this notebook is hidden for better readability. To toggle on/off, click <a href="javascript:code_toggle()">here</a>.
</p>
</div>
</div>
</div>


<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Assessing-Stability-of-Unsupervised-Clusterings">Assessing Stability of Unsupervised Clusterings<a class="anchor-link" href="#Assessing-Stability-of-Unsupervised-Clusterings">&#182;</a></h1><p>Dylan Rogerson<br>
June 24th, 2016</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In data analysis we often use unsupervised clustering methods to allow us to assess the structure of unlabeled data. Here at Activision, an easy example would be to use one of these methods to characterize our players. A highly engaged player who's been with us for years has a different concept of the game from a newer player who just picked up a controller for the first time. When we sift through our data we might expect to see groups of more and less experienced players, calling these players 'Hardcore' and 'Newbie', adding perhaps a third category for 'Midcore' (players that have played a bit, but aren't Hardcore). But what does the data actually tell us? What groups naturally arise out of the data itself? Which variables should we consider and how do these variables define our groups? These are all areas where machine learning and unsupervised clustering methods in particular can help out.</p>
<p>The topic today assumes you have a working knowledge around unsupervised methods. In particular we will focus on K-means clustering, a popular method in the space. As such there are few a properties that we would like our final segmentation to have:</p>
<p>1) We want our work to be reproducible in the same dataset. While different distance metrics and clustering methods may lead to different interpretations of the data, we at least strive to get the same interpretations for the same method in the same dataset.</p>
<p>2) We want to pick a 'good' number of clusters, k. Traditionally we pick k from an information theory or explained varience approach where our goal is to have a clustering that does a good job of explaining the dataset (<a href="https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set">https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set</a>). We'll see that we can further improve our determination of k by picking a clustering that is also stable.</p>
<p>3) We want our segments to be interpretable and actionable. This in a way limits our number of clusters. Too many segments and we lose our ability to interpret the clusters and therefore create an effective action plan. Too few and we might risk generalizing our audience, creating a simplistic treatment and missing the opportunity for a more tailored and effective approach.</p>
<p>Most of the work done here focuses on reseach from 'Clustering Stability: An Overview' by Luxburg 2010 (<a href="http://arxiv.org/abs/1007.1075">http://arxiv.org/abs/1007.1075</a>). This paper is definitely worth a read through and gives a strong background on the sources of instability and what others are doing in the field to address it.</p>
<p>There's a lot to digest here so let's start with a dataset (<a href="https://www.kaggle.com/census/2013-american-community-survey">https://www.kaggle.com/census/2013-american-community-survey</a>). The linked dataset is the 2013 American Community Survey which contains a great wealth of information: a combination of tax data and surveys about house electronics.</p>
<p>Today let's focus on the wealth distribution of Americans. We would like to see how much people work and where their earning comes from (including investing or other sources of income). Additionally, we expect this behavior to be different for different age groups and levels of education. Let's throw all of this together to see if can find identifiable groups.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-Dataset">The Dataset<a class="anchor-link" href="#The-Dataset">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-r"><pre><span></span><span class="kp">setwd</span><span class="p">(</span><span class="s">&quot;D:/Work Directory&quot;</span><span class="p">)</span>


<span class="c1">#install.packages(&quot;flexclust&quot;,repos=&quot;http://cran.stat.ucla.edu/&quot;)</span>

<span class="c1">#Turn Off Warnings</span>
<span class="kp">options</span><span class="p">(</span>warn<span class="o">=</span><span class="m">-1</span><span class="p">)</span>

<span class="c1"># Visualize Correlations</span>
<span class="kn">library</span><span class="p">(</span>corrplot<span class="p">)</span>
<span class="c1"># Speed up hclust</span>
<span class="kn">library</span><span class="p">(</span>fastcluster<span class="p">)</span>
<span class="c1"># For Heatmaps.2</span>
<span class="kn">library</span><span class="p">(</span>gplots<span class="p">)</span>
<span class="c1"># Plotting Library</span>
<span class="kn">library</span><span class="p">(</span>ggplot2<span class="p">)</span>
<span class="c1"># Library to Color our Heatmaps</span>
<span class="kn">library</span><span class="p">(</span>RColorBrewer<span class="p">)</span>
<span class="c1"># Package for Determining Cutoff for Cluster Size Based on Fit to Data</span>
<span class="kn">library</span><span class="p">(</span>GMD<span class="p">)</span>
<span class="c1">#For scoring K-means on a new Dataset</span>
<span class="kn">library</span><span class="p">(</span>flexclust<span class="p">)</span>


<span class="c1">#Turn On Warnings</span>
<span class="kp">options</span><span class="p">(</span>warn<span class="o">=</span><span class="m">0</span><span class="p">)</span>

<span class="c1"># Creating a palette for Heatmaps</span>
mypalette <span class="o">&lt;-</span> brewer.pal<span class="p">(</span><span class="m">10</span><span class="p">,</span><span class="s">&quot;RdBu&quot;</span><span class="p">)</span>

<span class="c1"># Our Survey Data</span>
datacs <span class="o">&lt;-</span> read.csv<span class="p">(</span><span class="s">&quot;./GAS Presentation/ss13pusa.csv&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-r"><pre><span></span>datprep1 <span class="o">&lt;-</span> datacs<span class="p">[</span>datacs<span class="o">$</span>AGEP<span class="o">&gt;=</span><span class="m">21</span><span class="p">,</span><span class="kt">c</span><span class="p">(</span><span class="s">&quot;WAGP&quot;</span><span class="p">,</span><span class="s">&quot;WKHP&quot;</span><span class="p">,</span><span class="s">&quot;SCHL&quot;</span><span class="p">,</span><span class="s">&quot;OIP&quot;</span><span class="p">,</span><span class="s">&quot;INTP&quot;</span><span class="p">,</span><span class="s">&quot;AGEP&quot;</span><span class="p">,</span><span class="s">&quot;SEX&quot;</span><span class="p">,</span><span class="s">&quot;pwgtp1&quot;</span><span class="p">,</span><span class="s">&quot;pwgtp2&quot;</span><span class="p">)]</span>

datprep1<span class="p">[</span><span class="kp">is.na</span><span class="p">(</span>datprep1<span class="p">)]</span> <span class="o">&lt;-</span> <span class="m">0</span>

<span class="c1"># Only include people who made money from wages or interest/dividends</span>
datprep1a <span class="o">&lt;-</span> <span class="p">(</span>datprep1<span class="p">[</span>datprep1<span class="o">$</span>WAGP <span class="o">&gt;</span> <span class="m">0</span> <span class="o">&amp;</span> datprep1<span class="o">$</span>INTP <span class="o">&gt;=</span> <span class="m">0</span><span class="p">,])</span>

<span class="kp">print</span><span class="p">(</span><span class="s">&quot;Total Number of Rows in Our Dataset&quot;</span><span class="p">)</span>
<span class="kp">nrow</span><span class="p">(</span>datprep1a<span class="p">)</span>
<span class="kp">print</span><span class="p">(</span><span class="s">&quot;First 6 Rows in Our Dataset&quot;</span><span class="p">)</span>
<span class="kp">head</span><span class="p">(</span>datprep1a<span class="p">)</span>
<span class="kp">print</span><span class="p">(</span><span class="s">&quot;Summary of Our Dataset&quot;</span><span class="p">)</span>
<span class="kp">summary</span><span class="p">(</span>datprep1a<span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>[1] &#34;Total Number of Rows in Our Dataset&#34;
</pre>
</div>
</div>

<div class="output_area">

<div class="output_html rendered_html output_subarea output_execute_result">
707659
</div>

</div>

<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>[1] &#34;First 6 Rows in Our Dataset&#34;
</pre>
</div>
</div>

<div class="output_area">

<div class="output_html rendered_html output_subarea output_execute_result">
<table>
<thead><tr><th></th><th scope=col>WAGP</th><th scope=col>WKHP</th><th scope=col>SCHL</th><th scope=col>OIP</th><th scope=col>INTP</th><th scope=col>AGEP</th><th scope=col>SEX</th><th scope=col>pwgtp1</th><th scope=col>pwgtp2</th></tr></thead>
<tbody>
	<tr><th scope=row>2</th><td>52000</td><td>40</td><td>20</td><td>0</td><td>0</td><td>55</td><td>2</td><td>45</td><td>51</td></tr>
	<tr><th scope=row>6</th><td>39000</td><td>40</td><td>21</td><td>0</td><td>0</td><td>63</td><td>2</td><td>481</td><td>575</td></tr>
	<tr><th scope=row>12</th><td>90000</td><td>48</td><td>16</td><td>0</td><td>0</td><td>59</td><td>1</td><td>83</td><td>58</td></tr>
	<tr><th scope=row>13</th><td>46000</td><td>40</td><td>18</td><td>0</td><td>0</td><td>56</td><td>2</td><td>69</td><td>49</td></tr>
	<tr><th scope=row>17</th><td>20000</td><td>25</td><td>21</td><td>0</td><td>0</td><td>72</td><td>1</td><td>60</td><td>163</td></tr>
	<tr><th scope=row>18</th><td>28000</td><td>40</td><td>19</td><td>0</td><td>0</td><td>52</td><td>2</td><td>29</td><td>91</td></tr>
</tbody>
</table>

</div>

</div>

<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>[1] &#34;Summary of Our Dataset&#34;
</pre>
</div>
</div>

<div class="output_area">


<div class="output_text output_subarea output_execute_result">
<pre>      WAGP             WKHP            SCHL           OIP         
 Min.   :     4   Min.   : 1.00   Min.   : 1.0   Min.   :    0.0  
 1st Qu.: 16000   1st Qu.:36.00   1st Qu.:16.0   1st Qu.:    0.0  
 Median : 34000   Median :40.00   Median :19.0   Median :    0.0  
 Mean   : 47441   Mean   :39.03   Mean   :18.6   Mean   :  404.2  
 3rd Qu.: 60000   3rd Qu.:43.00   3rd Qu.:21.0   3rd Qu.:    0.0  
 Max.   :660000   Max.   :99.00   Max.   :24.0   Max.   :83000.0  
      INTP             AGEP            SEX            pwgtp1      
 Min.   :     0   Min.   :21.00   Min.   :1.000   Min.   : -28.0  
 1st Qu.:     0   1st Qu.:32.00   1st Qu.:1.000   1st Qu.:  36.0  
 Median :     0   Median :44.00   Median :1.000   Median :  75.0  
 Mean   :  1465   Mean   :44.22   Mean   :1.484   Mean   : 103.3  
 3rd Qu.:     0   3rd Qu.:55.00   3rd Qu.:2.000   3rd Qu.: 131.0  
 Max.   :300000   Max.   :95.00   Max.   :2.000   Max.   :2494.0  
     pwgtp2      
 Min.   :  -8.0  
 1st Qu.:  36.0  
 Median :  75.0  
 Mean   : 103.4  
 3rd Qu.: 131.0  
 Max.   :2420.0  </pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Again, today we're going to focus on the wealth distribution on Americans. We'll segment people based off of the following attributes and see what the data tells us. We're also focused more on the stability methodology, so if you like to clean your data differently or use a different clustering method, go for it!</p>
<p>The variables used in clustering:</p>
<p>WAGP = Wages in the past 12 Months<br>
WKHP = Working Hours Per Week<br>
SCHL = Educational Attainment (Basically your level of education - non-linear)<br>
OIP  = All other income past 12 months<br>
INTP = Interest, dividends and net rental income past 12 months<br>
AGEP = Age</p>
<p>Other variables worth mentioning:</p>
<p>SEX  = 1 Male 2 Female<br>
pwgtp1 = A weight replicate<br>
pwgtp2 = A different weight replicate</p>
<p>While most of the variables seem straightforward, we should cover weight replicates. They're included in the survey because the people surveyed are not represented equally across the general population. By including these weights in measurements (such as weighted averages). You can get a more accurate picture. For the sake of simplicity, today we're going to ignore this field, but if you want to calculate individual metrics, you should take this variable into account.</p>
<p>Secondly, when we started our investigation we included sex, however there didn't seem to be a drastic change in the interpretation of groups when sex was introduced. Effectively, we ended up just splitting existing groups by gender. Since this variable increased the number of segments without adding any new interpretation or information, we decided to drop this variable.</p>
<p>We also wanted to look at working adults (or those earning interest) and concentrated on people of at least 21 years of age.</p>
<p>Our final dataset includes 707k people.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Our-Method-for-Today">Our Method for Today<a class="anchor-link" href="#Our-Method-for-Today">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For our approach today we'll focus on using a popular unsupervised clustering method, K-means. Even though this method is widely used for it's robustness and versitility. There are several assumptions that are relevant to K-means as well as drawbacks (clusters tend to be equally sized and the distribution of clusters is assumed to be spherical to name a few). For a more detailed discussion of the assumptions that go into the method feel free to check out <a href="http://stats.stackexchange.com/questions/133656/how-to-understand-the-drawbacks-of-k-means">http://stats.stackexchange.com/questions/133656/how-to-understand-the-drawbacks-of-k-means</a>.</p>
<p>Working with our dataset. We'll follow these steps:</p>
<p>1) First we scale the data set (subtract the mean and divide by the standard deviation for each variables) in order to evenly weight each variable. K-Means can also be sensitive to outliers (since it's concerned with means instead of medians) and so we also curb outliers in the data set to an absolute maximum of 2 standard deviations. In other words, if the absolute value of the datapoint is over 2, we set it to 2. Notice that we also create a train and holdout dataset. In the future we'll want to compare how different clusterings perform on the same dataset.</p>
<p>2) Run the resulting data through PCA, cutting out the last loading and leaving 93% of the varience. This helps reduce overweighting of variables in a highly correlated dataset. Since there is not a high degree of correlation in our variables this will not have a strong effect, however it has become a standard procedure that has many side benefits we've come to appreciate. Additionally, like K, there is debate as to what makes a 'good' cutoff and how many loadings explain enough of the varience in the data. Cutoffs in the range of 80-90% are common in the space.</p>
<p>3) Since we're using K-means we need to pick K. We can perform a clustering methodology or test to find a starting value for the number of clusters. There are a variety of methods to employ here (as mentioned above and in <a href="https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set">https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set</a>) though we'll constrain ourselves to evaluating a dendrogram from a hierarchical clustering of the dataset.</p>
<p>4) Seed K-means. The typical implementation of the K-means algorithm selects the initial centers randomly from the dataset. There are stronger methods for initalizing K-means to more accurately cover the space of the data and converge to the global minimum in the dataset quickly. Such methods are outlined in Bubeck 2009 (<a href="http://www.jmlr.org/papers/volume10/bubeck09a/bubeck09a.pdf">http://www.jmlr.org/papers/volume10/bubeck09a/bubeck09a.pdf</a>) and Dasgupta and Schulman 2007 (<a href="http://dl.acm.org/citation.cfm?id=1248666">http://dl.acm.org/citation.cfm?id=1248666</a>) and simplified in Luxburg 2010.</p>
<p>5) Finally we'll use this seed to initialize K-means on a subsample of our training dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Prep the Full Dataset</span>

datprep2<span class="o">&lt;-</span>datprep1a<span class="p">[,</span><span class="m">1</span><span class="o">:</span><span class="m">6</span><span class="p">]</span>
datprep4 <span class="o">&lt;-</span> <span class="kp">apply</span><span class="p">(</span>datprep2<span class="p">,</span><span class="m">2</span><span class="p">,</span><span class="kp">scale</span><span class="p">)</span>

<span class="c1">#Curb Outliers</span>
datprep4<span class="p">[</span>datprep4<span class="o">&gt;</span><span class="m">2</span><span class="p">]</span><span class="o">&lt;-</span><span class="m">2</span>
datprep4<span class="p">[</span>datprep4<span class="o">&lt;</span><span class="p">(</span><span class="m">-2</span><span class="p">)]</span><span class="o">&lt;-</span><span class="p">(</span><span class="m">-2</span><span class="p">)</span>

<span class="c1">#Perform PCA</span>

pcadat<span class="o">&lt;-</span>prcomp<span class="p">(</span>datprep4<span class="p">,</span>
               center <span class="o">=</span> <span class="kc">TRUE</span><span class="p">,</span>
               scale. <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>

<span class="kp">print</span><span class="p">(</span><span class="s">&quot;Summary of the PCA Components of Our Dataset&quot;</span><span class="p">)</span>
<span class="kp">summary</span><span class="p">(</span>pcadat<span class="p">)</span>

<span class="c1">#Cut off the last loading</span>
datprep5<span class="o">&lt;-</span>pcadat<span class="o">$</span>x
datprep6<span class="o">&lt;-</span>datprep5<span class="p">[,</span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="kp">ncol</span><span class="p">(</span>datprep5<span class="p">)</span><span class="m">-1</span><span class="p">)]</span>

randomSample<span class="o">&lt;-</span>runif<span class="p">(</span><span class="kp">nrow</span><span class="p">(</span>datprep1a<span class="p">))</span>

holdout<span class="o">&lt;-</span>datprep6<span class="p">[</span>randomSample<span class="o">&gt;=</span><span class="m">0.9</span><span class="p">,]</span> <span class="c1">#Holdout for Cluster Label Comparision (Rand Index)</span>
train<span class="o">&lt;-</span>datprep6<span class="p">[</span>randomSample<span class="o">&lt;</span><span class="m">0.9</span><span class="p">,]</span> <span class="c1">#Data to Train the Clustering Models on</span>

trainRaw<span class="o">&lt;-</span>datprep2<span class="p">[</span>randomSample<span class="o">&lt;</span><span class="m">0.9</span><span class="p">,]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>[1] &#34;Summary of the PCA Components of Our Dataset&#34;
</pre>
</div>
</div>

<div class="output_area">


<div class="output_text output_subarea output_execute_result">
<pre>Importance of components:
                          PC1    PC2    PC3    PC4    PC5     PC6
Standard deviation     1.3162 1.0554 0.9965 0.9682 0.8981 0.64545
Proportion of Variance 0.2887 0.1856 0.1655 0.1562 0.1344 0.06943
Cumulative Proportion  0.2887 0.4744 0.6399 0.7961 0.9306 1.00000</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Determining-The-Number-of-Clusters-From-a-Dendrogram">Determining The Number of Clusters From a Dendrogram<a class="anchor-link" href="#Determining-The-Number-of-Clusters-From-a-Dendrogram">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As an aside I'd like to address how to interpret a Hierarchical Clustering Dendrogram. This is one of many ways (similar to the Elbow Plot method) to determine the number of clusters and there is some art to it.</p>
<p>First a dendrogram shows where our splits occur in our dataset as we increase the number of clusters. The vertical height denotes how much error we incur when we say that every datapoint is actually its closest centroid or the intercluster dissimilarity. In this way it's similar to an Elbow Plot. We're looking for the biggest change in error (in this case in height) that will meaningfully describe the data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-r"><pre><span></span><span class="c1"># Perform Hclust on a 2k sample</span>
samp <span class="o">&lt;-</span> datprep6<span class="p">[</span><span class="kp">sample</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="kp">nrow</span><span class="p">(</span>datprep6<span class="p">),</span><span class="m">2000</span><span class="p">),]</span>
d <span class="o">&lt;-</span> dist<span class="p">(</span>samp<span class="p">,</span> method <span class="o">=</span> <span class="s">&quot;euclidean&quot;</span><span class="p">)</span>
fit <span class="o">&lt;-</span> hclust<span class="p">(</span>d<span class="p">,</span> method <span class="o">=</span> <span class="s">&quot;ward.D&quot;</span><span class="p">)</span> 

<span class="kp">print</span><span class="p">(</span><span class="s">&quot;A Visualization of Our Hierarchical Clustering Dendogram&quot;</span><span class="p">)</span>
plot<span class="p">(</span>fit<span class="p">)</span>

ksize <span class="o">&lt;-</span> <span class="m">4</span> <span class="c1">#Define size of the cluster</span>
groups <span class="o">&lt;-</span> cutree<span class="p">(</span>fit<span class="p">,</span> k <span class="o">=</span> ksize<span class="p">)</span>
centroids <span class="o">&lt;-</span> aggregate<span class="p">(</span>samp<span class="p">,</span> by <span class="o">=</span> <span class="kt">list</span><span class="p">(</span>groups<span class="p">),</span> FUN <span class="o">=</span> <span class="kp">mean</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>[1] &#34;A Visualization of Our Hierarchical Clustering Dendogram&#34;
</pre>
</div>
</div>

<div class="output_area">


<div class="output_png output_subarea ">
<img src="data:image/png;base64,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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Looking top to bottom we see that the split to 2 clusters causes a very big drop in error and the next biggest splits occurs at 4 (3 is a pretty negligable difference). So 4 clusters seems like a good start.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-Initialization-Method">The Initialization Method<a class="anchor-link" href="#The-Initialization-Method">&#182;</a></h3><p>In point 4 of 'A Clustering Method' we mentioned the R implementation of K-means initializes off of random points in the dataset. The largest issue here is that of coverage, and outliers. Are we picking points that cover the full space of the data without ignoring outliers? A robust initialization scheme for this issue can be found in Dasgupta and Schulman (2007) / Bubeck (2009) and is best described for K-means in Luxburg (2010).</p>
<p>We'll initialize with the following procedure (copied directly from Luxburg (2010):</p>
<p>1) Select L preliminary centers uniformly at random from the given data set, where L ≈ K log(K).</p>
<p>2) Run one step of K-means, that is assign the data points to the preliminary centers and re-adjust the centers once.</p>
<p>3) Remove all centers for which the mass of the assigned data points is smaller than p0 = 1/(2 L). In Luxburg, they quote approximately 1/L, however we've found 1/(2 L) works quite well. Additionally, is this doesn't give us greater than K clusters to choose from, we simply initialize with the K largest clusters.</p>
<p>4) Among the remaining centers, select K centers by the following procedure:<br>
    a) Choose the first center uniformly at random.<br>
    b) Repeat until K centers are selected: Select the next center as the one that maximizes the minimum distance to the centers already selected.</p>
<p>The code block below executes the above steps and outputs our initial centers.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Turn Off Warnings</span>
<span class="kp">options</span><span class="p">(</span>warn<span class="o">=</span><span class="m">-1</span><span class="p">)</span>

ksize <span class="o">&lt;-</span> <span class="m">4</span>

  <span class="c1">##Initialization Method For Kmeans Described in Dasgupta and Schulman (2007)</span>
  
  initialKmeans <span class="o">&lt;-</span> kmeans<span class="p">(</span>datprep6<span class="p">,</span> <span class="kp">ceiling</span><span class="p">(</span>ksize<span class="o">*</span><span class="kp">log</span><span class="p">(</span>ksize<span class="p">)),</span>iter.max <span class="o">=</span> <span class="m">1</span><span class="p">)</span>
  validCenters <span class="o">&lt;-</span> initialKmeans<span class="o">$</span>size<span class="o">/</span><span class="kp">nrow</span><span class="p">(</span>datprep6<span class="p">)</span><span class="o">*</span><span class="kp">ceiling</span><span class="p">(</span>ksize<span class="o">*</span><span class="kp">log</span><span class="p">(</span>ksize<span class="p">))</span> <span class="o">&gt;</span> <span class="m">1</span><span class="o">/</span><span class="m">2</span>
  centersNoOutliers <span class="o">&lt;-</span> initialKmeans<span class="o">$</span>centers<span class="p">[</span>validCenters<span class="p">,]</span>
  
  
<span class="kr">if</span> <span class="p">(</span><span class="kp">sum</span><span class="p">(</span>validCenters<span class="p">)</span> <span class="o">&gt;</span> ksize<span class="p">)</span> <span class="p">{</span>
  
  nextCenter <span class="o">&lt;-</span> centersNoOutliers<span class="p">[</span><span class="m">1</span><span class="p">,]</span> <span class="c1">#Start with a Random Center</span>
  initialCenters <span class="o">&lt;-</span> <span class="kt">data.frame</span><span class="p">(</span><span class="kp">t</span><span class="p">(</span>nextCenter<span class="p">))</span>
  centersConsidered <span class="o">&lt;-</span> <span class="m">2</span><span class="o">:</span><span class="kp">nrow</span><span class="p">(</span>centersNoOutliers<span class="p">)</span> <span class="c1">#Keep track of the centers that can still be added</span>
  
  <span class="kr">for</span><span class="p">(</span>i <span class="kr">in</span> <span class="m">1</span><span class="o">:</span><span class="p">(</span>ksize<span class="m">-1</span><span class="p">)){</span>
    
    k2<span class="o">&lt;-</span><span class="kt">matrix</span><span class="p">(,</span>ncol <span class="o">=</span> <span class="kp">nrow</span><span class="p">(</span>centersNoOutliers<span class="p">),</span>nrow <span class="o">=</span> i<span class="p">)</span>
    
    <span class="kr">for</span><span class="p">(</span>k <span class="kr">in</span> <span class="m">1</span><span class="o">:</span>i<span class="p">)</span> <span class="p">{</span>
    
    <span class="kr">for</span><span class="p">(</span> j <span class="kr">in</span> <span class="m">1</span><span class="o">:</span><span class="kp">nrow</span><span class="p">(</span>centersNoOutliers<span class="p">))</span> <span class="p">{</span>
      k2<span class="p">[</span>k<span class="p">,</span>j<span class="p">]</span><span class="o">&lt;-</span><span class="kp">sum</span><span class="p">((</span>centersNoOutliers<span class="p">[</span>j<span class="p">,]</span><span class="o">-</span>initialCenters<span class="p">[</span>k<span class="p">,])</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
       <span class="p">}</span>
    <span class="p">}</span> <span class="c1">#Create a Distance Matrix between the centers currently selected and all centers</span>
    
    <span class="kr">if</span><span class="p">(</span>i <span class="o">==</span> <span class="m">1</span><span class="p">){</span>
      k3 <span class="o">&lt;-</span> k2<span class="p">}</span><span class="kp">else</span><span class="p">{</span>
    clusterWithMaxMinDistance <span class="o">&lt;-</span> <span class="kp">which.max</span><span class="p">(</span><span class="kp">apply</span><span class="p">(</span>k2<span class="p">[,</span>centersConsidered<span class="p">],</span><span class="m">1</span><span class="p">,</span>FUN<span class="o">=</span><span class="kp">min</span><span class="p">))</span>
    k3 <span class="o">&lt;-</span> k2<span class="p">[</span>clusterWithMaxMinDistance<span class="p">,]</span>
    <span class="p">}</span> <span class="c1">#Calculating relevant distances to find the cluster that maximizes the minimum distance to the centers already selected.</span>
  
    nextCenter <span class="o">&lt;-</span> centersNoOutliers<span class="p">[</span>centersConsidered<span class="p">[</span><span class="kp">which.max</span><span class="p">(</span> k3<span class="p">[</span>centersConsidered<span class="p">])],]</span> 
      <span class="c1">#Select the center which maximizes the minimum distance to one of the centers already selected</span>
    centersConsidered <span class="o">&lt;-</span> centersConsidered<span class="p">[</span><span class="o">-</span><span class="kp">which.max</span><span class="p">(</span> k3<span class="p">[</span>centersConsidered<span class="p">])]</span>
      <span class="c1">#One selected we have to remove it from the centers that are still up for selection</span>
    initialCenters <span class="o">&lt;-</span> <span class="kp">rbind</span><span class="p">(</span>initialCenters<span class="p">,</span>nextCenter<span class="p">)</span>
      <span class="c1">#And finally add the new center to the list of initialization centers for K-means.</span>
    
  <span class="p">}</span>
  
<span class="p">}</span><span class="kr">else</span> <span class="p">{</span>initialCenters <span class="o">&lt;-</span> centersNoOutliers <span class="p">}</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Running-our-First-K-Means-Clustering">Running our First K-Means Clustering<a class="anchor-link" href="#Running-our-First-K-Means-Clustering">&#182;</a></h3><p>Now that we have our inital centers we can run K-means. Let's also save our initial clustering (called 'initialSegmentation') in the code so we can compare it to other clusterings that we run.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Run K means on the whole dataset</span>

PCAKmeans <span class="o">&lt;-</span> kmeans<span class="p">(</span>datprep6<span class="p">,</span> initialCenters<span class="p">)</span>
clustersize <span class="o">&lt;-</span> PCAKmeans<span class="o">$</span>size<span class="o">/</span><span class="kp">sum</span><span class="p">(</span>PCAKmeans<span class="o">$</span>size<span class="p">)</span><span class="o">*</span><span class="m">100</span>
initialSegmentation <span class="o">&lt;-</span> aggregate<span class="p">(</span>datprep4<span class="p">,</span>by <span class="o">=</span> <span class="kt">list</span><span class="p">(</span>PCAKmeans<span class="o">$</span>cluster<span class="p">),</span>FUN <span class="o">=</span> <span class="kp">mean</span><span class="p">)</span>
initialSegmentation <span class="o">&lt;-</span> initialSegmentation<span class="p">[,</span><span class="m">2</span><span class="o">:</span><span class="kp">ncol</span><span class="p">(</span>initialSegmentation<span class="p">)]</span>

<span class="kp">print</span><span class="p">(</span><span class="s">&quot;Our First Attempt at Clustering&quot;</span><span class="p">)</span>
<span class="kp">print</span><span class="p">(</span><span class="s">&quot;Segment Mean Values&quot;</span><span class="p">)</span>
<span class="kt">data.frame</span><span class="p">(</span><span class="kp">round</span><span class="p">(</span>aggregate<span class="p">(</span>datprep2<span class="p">,</span>by <span class="o">=</span> <span class="kt">list</span><span class="p">(</span>PCAKmeans<span class="o">$</span>cluster<span class="p">),</span>FUN <span class="o">=</span> <span class="kp">mean</span><span class="p">),</span><span class="m">2</span><span class="p">),</span>clustersize<span class="p">)</span>

<span class="c1">#Turn On Warnings</span>
<span class="kp">options</span><span class="p">(</span>warn<span class="o">=</span><span class="m">0</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>[1] &#34;Our First Attempt at Clustering&#34;
[1] &#34;Segment Mean Values&#34;
</pre>
</div>
</div>

<div class="output_area">

<div class="output_html rendered_html output_subarea output_execute_result">
<table>
<thead><tr><th></th><th scope=col>Group.1</th><th scope=col>WAGP</th><th scope=col>WKHP</th><th scope=col>SCHL</th><th scope=col>OIP</th><th scope=col>INTP</th><th scope=col>AGEP</th><th scope=col>clustersize</th></tr></thead>
<tbody>
	<tr><th scope=row>1</th><td>1</td><td>25599.97</td><td>36.35</td><td>18.68</td><td>32.49</td><td>83.06</td><td>30.49</td><td>35.23773</td></tr>
	<tr><th scope=row>2</th><td>2</td><td>100249.4</td><td>47.24</td><td>20.86</td><td>17.02</td><td>4278</td><td>48.6</td><td>28.11425</td></tr>
	<tr><th scope=row>3</th><td>3</td><td>32766.6</td><td>37.73</td><td>18.59</td><td>10064.16</td><td>1175.44</td><td>45.13</td><td>3.758307</td></tr>
	<tr><th scope=row>4</th><td>4</td><td>27376.87</td><td>35.04</td><td>16.6</td><td>29.7</td><td>574.26</td><td>55.07</td><td>32.88971</td></tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Results">Results<a class="anchor-link" href="#Results">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So what did we get back from all of this? We see 4 segments.</p>
<p>Group 1 - Our Young Workforce: Not just the youngest segment, but the one with the least amount of investing and other sources of income. Many of these people may be part-time and still in college.</p>
<p>Group 2 - High Education / Work Week: This group is comprised of professionals with a good deal of experience in age and education (and a moderate amount of income from other sources.</p>
<p>Group 3 - Other Sources of Income: This very small group (3.8%) relies on other sources of income as well as a standard wage. While similar in age to the High Education group, they have slightly less education.</p>
<p>Group 4 - Low Education / Work Week: This group is comprised of older individuals with lower schooling and income.</p>
<p>But as we'll see, they're not perfectly stable.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Stability-Testing">Stability Testing<a class="anchor-link" href="#Stability-Testing">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we're done right? We picked our cutoff by looking at a dendogram (hey it looks like 4 clusters will work fine) and maybe we even run this whole thing a few times on different datasets to make sure we see the same kind of clusters. Unfortunately this isn't the whole story. We can easily decieve ourselves into thinking we have a stable result and unsupervised clustering methods have a particularly nasty habit of 'jumping around' under different samples of data (more on that later). Running this clustering several times may produce different results. In fact let's do just that.</p>
<p>In this method we're comparing each subsequent segmentation to our initial segmentation (first run). How often subsequent clusterings agree will dictate whether we're happy with current clustering methodology. To say it another way, if we get different clusters every time, our work isn't reproducible.</p>
<p>Here we sample 100,000 points from our training dataset and go through the same steps we mentioned in sections 'The Initial Segmentation Method', 'Running our First K-mean Clustering Method' and 'Results' 10 times. The first time we save our result as the 'initialSegmentation'. We then compare the next 9 iterations (or runs) to the initial segmentation.</p>
<p>Every time we perform a new run we determine our labels from scratch. That is to say that cluster 1 from our initial segmentation may be 'Low Education / Work Week' and cluster 1 from our second run may be 'Our Young Workforce'. In order to make sure that cluster 1 is always talking about 'Low Education / Work Week', we compare each clusters in run 2 to the initial one and assign labels based on the minimum euclidean distance between each cluster (ignoring the clusters we've already assigned). For instance we might find that cluster 3 in run 2 is very close to cluster 1 from our intial run, and therefore our best guess for 'Low Education / Work Week'. We then reassign cluster 3 in run 2 as cluster 1 and move through the rest of the clusters in run 2 reassigning as necessary. You can see the code for this in the section "Reorder Labels to Match First Clustering" below.</p>
<p>Once all of these clusters have been relabeled we will have the minimum cluster to cluster distance between these segmentations. Dividing by the number of clusters gives us the 'Mean Cluster to Cluster Distance' reported in the output. If this number is large then our new segmentation is quite dissimilar from our inital segmentation.</p>
<p>While this is a helpful measurement of cluster dissimilarity a far more robust measure of cluster dissimilarity is the Rand Index (refered to in Luxberg 2010). We'll report this too and after we see some results we'll go into a bit more depth on exactly what the Rand Index is and how to interpret our findings.</p>
<p>For brevity we'll suppress the code, but feel free to expand it.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Turn Off Warnings</span>
<span class="kp">options</span><span class="p">(</span>warn<span class="o">=</span><span class="m">-1</span><span class="p">)</span>

ksize<span class="o">&lt;-</span><span class="m">4</span>
bootstraps<span class="o">&lt;-</span><span class="m">10</span>

assignmentResults<span class="o">&lt;-</span><span class="kt">data.frame</span><span class="p">(</span><span class="kt">matrix</span><span class="p">(,</span>nrow <span class="o">=</span> bootstraps<span class="p">,</span> ncol <span class="o">=</span> <span class="m">1000</span><span class="p">))</span>
randResults<span class="o">&lt;-</span><span class="kt">c</span><span class="p">()</span>


<span class="kr">for</span> <span class="p">(</span>iclustering <span class="kr">in</span> <span class="m">1</span><span class="o">:</span>bootstraps<span class="p">)</span> <span class="p">{</span>
  
  
  samplingIntegers<span class="o">&lt;-</span><span class="kp">sample</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="kp">nrow</span><span class="p">(</span>train<span class="p">),</span><span class="m">100000</span><span class="p">)</span>
  
  datprep7<span class="o">&lt;-</span>train<span class="p">[</span>samplingIntegers<span class="p">,]</span>
  datprepRaw<span class="o">&lt;-</span>trainRaw<span class="p">[</span>samplingIntegers<span class="p">,]</span>
  
  <span class="c1">##Initialization Method For Kmeans Described in Dasgupta and Schulman (2007)</span>
  
  initialKmeans <span class="o">&lt;-</span> kmeans<span class="p">(</span>datprep7<span class="p">,</span> <span class="kp">ceiling</span><span class="p">(</span>ksize<span class="o">*</span><span class="kp">log</span><span class="p">(</span>ksize<span class="p">)),</span>iter.max <span class="o">=</span> <span class="m">1</span><span class="p">)</span>
  validCenters <span class="o">&lt;-</span> initialKmeans<span class="o">$</span>size<span class="o">/</span><span class="kp">nrow</span><span class="p">(</span>datprep7<span class="p">)</span><span class="o">*</span><span class="kp">ceiling</span><span class="p">(</span>ksize<span class="o">*</span><span class="kp">log</span><span class="p">(</span>ksize<span class="p">))</span> <span class="o">&gt;</span> <span class="m">1</span><span class="o">/</span><span class="m">2</span>
  centersNoOutliers <span class="o">&lt;-</span> initialKmeans<span class="o">$</span>centers<span class="p">[</span>validCenters<span class="p">,]</span>
  
  
<span class="kr">if</span> <span class="p">(</span><span class="kp">sum</span><span class="p">(</span>validCenters<span class="p">)</span> <span class="o">&gt;</span> ksize<span class="p">)</span> <span class="p">{</span>
  
  nextCenter <span class="o">&lt;-</span> centersNoOutliers<span class="p">[</span><span class="m">1</span><span class="p">,]</span> <span class="c1">#Start with a Random Center</span>
  initialCenters <span class="o">&lt;-</span> <span class="kt">data.frame</span><span class="p">(</span><span class="kp">t</span><span class="p">(</span>nextCenter<span class="p">))</span>
  centersConsidered <span class="o">&lt;-</span> <span class="m">2</span><span class="o">:</span><span class="kp">nrow</span><span class="p">(</span>centersNoOutliers<span class="p">)</span> <span class="c1">#Keep track of the centers that can still be added</span>
  
  <span class="kr">for</span><span class="p">(</span>i <span class="kr">in</span> <span class="m">1</span><span class="o">:</span><span class="p">(</span>ksize<span class="m">-1</span><span class="p">)){</span>
    
    k2<span class="o">&lt;-</span><span class="kt">matrix</span><span class="p">(,</span>ncol <span class="o">=</span> <span class="kp">nrow</span><span class="p">(</span>centersNoOutliers<span class="p">),</span>nrow <span class="o">=</span> i<span class="p">)</span>
    
    <span class="kr">for</span><span class="p">(</span>k <span class="kr">in</span> <span class="m">1</span><span class="o">:</span>i<span class="p">)</span> <span class="p">{</span>
    
    <span class="kr">for</span><span class="p">(</span> j <span class="kr">in</span> <span class="m">1</span><span class="o">:</span><span class="kp">nrow</span><span class="p">(</span>centersNoOutliers<span class="p">))</span> <span class="p">{</span>
      k2<span class="p">[</span>k<span class="p">,</span>j<span class="p">]</span><span class="o">&lt;-</span><span class="kp">sum</span><span class="p">((</span>centersNoOutliers<span class="p">[</span>j<span class="p">,]</span><span class="o">-</span>initialCenters<span class="p">[</span>k<span class="p">,])</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
       <span class="p">}</span>
    <span class="p">}</span> <span class="c1">#Create a Distance Matrix between the centers currently selected and all centers</span>
    
    <span class="kr">if</span><span class="p">(</span>i <span class="o">==</span> <span class="m">1</span><span class="p">){</span>
      k3 <span class="o">&lt;-</span> k2<span class="p">}</span><span class="kp">else</span><span class="p">{</span>
    clusterWithMaxMinDistance <span class="o">&lt;-</span> <span class="kp">which.max</span><span class="p">(</span><span class="kp">apply</span><span class="p">(</span>k2<span class="p">[,</span>centersConsidered<span class="p">],</span><span class="m">1</span><span class="p">,</span>FUN<span class="o">=</span><span class="kp">min</span><span class="p">))</span>
    k3 <span class="o">&lt;-</span> k2<span class="p">[</span>clusterWithMaxMinDistance<span class="p">,]</span>
    <span class="p">}</span> <span class="c1">#Calculating relevant distances to find the cluster that maximizes the minimum distance to the centers already selected.</span>
  
    nextCenter <span class="o">&lt;-</span> centersNoOutliers<span class="p">[</span>centersConsidered<span class="p">[</span><span class="kp">which.max</span><span class="p">(</span> k3<span class="p">[</span>centersConsidered<span class="p">])],]</span> 
      <span class="c1">#Select the center which maximizes the minimum distance to one of the centers already selected</span>
    centersConsidered <span class="o">&lt;-</span> centersConsidered<span class="p">[</span><span class="o">-</span><span class="kp">which.max</span><span class="p">(</span> k3<span class="p">[</span>centersConsidered<span class="p">])]</span>
      <span class="c1">#One selected we have to remove it from the centers that are still up for selection</span>
    initialCenters <span class="o">&lt;-</span> <span class="kp">rbind</span><span class="p">(</span>initialCenters<span class="p">,</span>nextCenter<span class="p">)</span>
      <span class="c1">#And finally add the new center to the list of initialization centers for K-means.</span>
    
  <span class="p">}</span>
  
<span class="p">}</span><span class="kr">else</span> <span class="p">{</span>initialCenters <span class="o">&lt;-</span> centersNoOutliers <span class="p">}</span>
  
  
  
  <span class="c1">#Now we do Kmeans</span>
  
  PCAKmeans <span class="o">&lt;-</span> kcca<span class="p">(</span>datprep7<span class="p">,</span> k <span class="o">=</span> <span class="kp">as.matrix</span><span class="p">(</span>initialCenters<span class="p">),</span> kccaFamily<span class="p">(</span><span class="s">&quot;kmeans&quot;</span><span class="p">),</span>simple<span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
  
  
  clustersize<span class="o">&lt;-</span>PCAKmeans<span class="o">@</span>clusinfo<span class="o">$</span>size<span class="o">/</span><span class="kp">sum</span><span class="p">(</span>PCAKmeans<span class="o">@</span>clusinfo<span class="o">$</span>size<span class="p">)</span>
  testcluster<span class="o">&lt;-</span>aggregate<span class="p">(</span>datprep7<span class="p">,</span>by<span class="o">=</span><span class="kt">list</span><span class="p">(</span>PCAKmeans<span class="o">@</span>cluster<span class="p">),</span>FUN <span class="o">=</span> <span class="kp">mean</span><span class="p">)</span>
  testcluster<span class="o">&lt;-</span>testcluster<span class="p">[,</span><span class="m">2</span><span class="o">:</span><span class="kp">ncol</span><span class="p">(</span>testcluster<span class="p">)]</span>
  testClusterRealValues <span class="o">&lt;-</span> aggregate<span class="p">(</span>datprepRaw<span class="p">,</span>by<span class="o">=</span><span class="kt">list</span><span class="p">(</span>PCAKmeans<span class="o">@</span>cluster<span class="p">),</span>FUN <span class="o">=</span> <span class="kp">mean</span><span class="p">)</span>
  
  
  <span class="c1">#Reorder Labels to Match First Clustering</span>
  <span class="kr">if</span><span class="p">(</span>iclustering<span class="o">==</span><span class="m">1</span><span class="p">)</span> <span class="p">{</span>
    truecluster<span class="o">&lt;-</span>testcluster
    initialSegmentation<span class="o">&lt;-</span>PCAKmeans
  <span class="p">}</span> <span class="kr">else</span> <span class="p">{</span>
    
    clustersconsidered<span class="o">&lt;-</span><span class="m">1</span><span class="o">:</span>ksize
    clusterscore2<span class="o">&lt;-</span> <span class="m">1</span><span class="o">:</span>ksize
    cluster2clusterdistance<span class="o">&lt;-</span><span class="m">0</span>
    
    
    <span class="kr">for</span> <span class="p">(</span> i <span class="kr">in</span> <span class="m">1</span><span class="o">:</span><span class="kp">nrow</span><span class="p">(</span>truecluster<span class="p">))</span> <span class="p">{</span>
      
      
      k2<span class="o">&lt;-</span><span class="kt">c</span><span class="p">()</span>
      <span class="kr">for</span><span class="p">(</span> j <span class="kr">in</span> <span class="m">1</span><span class="o">:</span><span class="kp">nrow</span><span class="p">(</span>testcluster<span class="p">))</span> <span class="p">{</span>
        k2<span class="p">[</span>j<span class="p">]</span><span class="o">&lt;-</span><span class="kp">sum</span><span class="p">((</span>testcluster<span class="p">[</span>j<span class="p">,]</span><span class="o">-</span>truecluster<span class="p">[</span>i<span class="p">,])</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
        
      <span class="p">}</span>
      clusterscore2<span class="p">[</span>i<span class="p">]</span><span class="o">&lt;-</span>clustersconsidered<span class="p">[</span><span class="kp">which.min</span><span class="p">(</span> k2<span class="p">[</span>clustersconsidered<span class="p">])]</span>
      cluster2clusterdistance<span class="o">&lt;-</span>cluster2clusterdistance <span class="o">+</span> <span class="kp">min</span><span class="p">(</span> k2<span class="p">[</span>clustersconsidered<span class="p">])</span>
      clustersconsidered<span class="o">&lt;-</span>clustersconsidered<span class="p">[</span><span class="o">-</span><span class="kp">which.min</span><span class="p">(</span>k2<span class="p">[</span>clustersconsidered<span class="p">])]</span>
      
    <span class="p">}</span>
  <span class="p">}</span> 
  
  <span class="c1">#If the first run create a table</span>
  
  <span class="kr">if</span> <span class="p">(</span>iclustering<span class="o">==</span><span class="m">1</span><span class="p">)</span> <span class="p">{</span>
    output<span class="o">&lt;-</span>testcluster
    output<span class="o">$</span>segment<span class="o">&lt;-</span><span class="m">1</span><span class="o">:</span>ksize
    output<span class="o">$</span>run<span class="o">&lt;-</span>iclustering
 
    outputraw <span class="o">&lt;-</span>   testClusterRealValues<span class="p">[,</span><span class="m">2</span><span class="o">:</span><span class="kp">ncol</span><span class="p">(</span>testClusterRealValues<span class="p">)]</span>
    outputraw<span class="o">$</span>segment<span class="o">&lt;-</span><span class="m">1</span><span class="o">:</span>ksize
    outputraw<span class="o">$</span>run<span class="o">&lt;-</span>iclustering
    
    <span class="c1">#Labeling the holdout dataset with the model and using it to calculate the Rand Index</span>
    labelsInitial<span class="o">&lt;-</span>predict<span class="p">(</span>initialSegmentation<span class="p">,</span>holdout<span class="p">)</span>
    assignmentResults<span class="p">[</span>iclustering<span class="p">,]</span><span class="o">&lt;-</span>labelsInitial<span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">]</span>
    randResults<span class="p">[</span>iclustering<span class="p">]</span> <span class="o">&lt;-</span> <span class="m">1</span>
    
    <span class="kp">print</span><span class="p">(</span> <span class="kp">paste</span><span class="p">(</span><span class="kt">c</span><span class="p">(</span><span class="s">&quot;Run                                   : &quot;</span><span class="p">,</span>iclustering<span class="p">),</span>collapse<span class="o">=</span><span class="s">&quot; &quot;</span> <span class="p">))</span>
    <span class="kp">print</span><span class="p">(</span> <span class="s">&quot;&quot;</span> <span class="p">)</span>
    
    
  <span class="p">}</span> <span class="kr">else</span> <span class="p">{</span>
      
  <span class="c1">#If any other run append to the table</span>
      
    new<span class="o">&lt;-</span>testcluster<span class="p">[</span>clusterscore2<span class="p">,]</span>
    new<span class="o">$</span>segment<span class="o">&lt;-</span><span class="m">1</span><span class="o">:</span>ksize
    new<span class="o">$</span>run<span class="o">&lt;-</span>iclustering
    output<span class="o">&lt;-</span><span class="kp">rbind</span><span class="p">(</span>output<span class="p">,</span>new<span class="p">)</span>

    rawCenters<span class="o">&lt;-</span>testClusterRealValues<span class="p">[</span>clusterscore2<span class="p">,]</span>
    rawCenters<span class="o">$</span>segment<span class="o">&lt;-</span><span class="m">1</span><span class="o">:</span>ksize
    rawCenters<span class="o">$</span>run<span class="o">&lt;-</span>iclustering
    outputraw<span class="o">&lt;-</span><span class="kp">rbind</span><span class="p">(</span>outputraw<span class="p">,</span>rawCenters<span class="p">[,</span><span class="m">2</span><span class="o">:</span><span class="kp">ncol</span><span class="p">(</span>rawCenters<span class="p">)])</span>
    
    <span class="c1">#Labeling the holdout dataset with the model and using it to calculate the Rand Index  </span>
    labelsTest<span class="o">&lt;-</span>predict<span class="p">(</span>PCAKmeans<span class="p">,</span>holdout<span class="p">)</span>
    labelsTest2<span class="o">&lt;-</span><span class="kp">factor</span><span class="p">(</span>labelsTest<span class="p">)</span>
    <span class="kp">levels</span><span class="p">(</span>labelsTest2<span class="p">)</span><span class="o">&lt;-</span><span class="kp">order</span><span class="p">(</span>clusterscore2<span class="p">)</span>
    stabilityMeasure<span class="o">&lt;-</span>randIndex<span class="p">(</span>labelsInitial<span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">],</span>labelsTest2<span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">])</span>
    assignmentResults<span class="p">[</span>iclustering<span class="p">,]</span><span class="o">&lt;-</span>labelsTest2<span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">]</span>
    randResults<span class="p">[</span>iclustering<span class="p">]</span> <span class="o">&lt;-</span> stabilityMeasure
    
    
    <span class="kp">print</span><span class="p">(</span> <span class="kp">paste</span><span class="p">(</span><span class="kt">c</span><span class="p">(</span><span class="s">&quot;Run                                   : &quot;</span><span class="p">,</span>iclustering<span class="p">),</span>collapse<span class="o">=</span><span class="s">&quot; &quot;</span> <span class="p">))</span>
    <span class="kp">print</span><span class="p">(</span> <span class="kp">paste</span><span class="p">(</span><span class="kt">c</span><span class="p">(</span><span class="s">&quot;Rand Index (Cluster Similarity)       : &quot;</span><span class="p">,</span>stabilityMeasure<span class="p">),</span>collapse<span class="o">=</span><span class="s">&quot; &quot;</span> <span class="p">))</span>
    <span class="kp">print</span><span class="p">(</span> <span class="kp">paste</span><span class="p">(</span><span class="kt">c</span><span class="p">(</span><span class="s">&quot;Mean Cluster to Cluster Distance      : &quot;</span><span class="p">,</span>cluster2clusterdistance<span class="o">/</span>ksize<span class="p">),</span>collapse<span class="o">=</span><span class="s">&quot; &quot;</span> <span class="p">))</span>
    <span class="kp">print</span><span class="p">(</span> <span class="s">&quot;&quot;</span> <span class="p">)</span>
    
    
  <span class="p">}</span>
<span class="p">}</span>

<span class="c1">#Turn On Warnings</span>
<span class="kp">options</span><span class="p">(</span>warn<span class="o">=</span><span class="m">0</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>[1] &#34;Run                                   :  1&#34;
[1] &#34;&#34;
[1] &#34;Run                                   :  2&#34;
[1] &#34;Rand Index (Cluster Similarity)       :  0.232962984867752&#34;
[1] &#34;Mean Cluster to Cluster Distance      :  14.6535690777866&#34;
[1] &#34;&#34;
[1] &#34;Run                                   :  3&#34;
[1] &#34;Rand Index (Cluster Similarity)       :  0.987185074113396&#34;
[1] &#34;Mean Cluster to Cluster Distance      :  0.00103289705216875&#34;
[1] &#34;&#34;
[1] &#34;Run                                   :  4&#34;
[1] &#34;Rand Index (Cluster Similarity)       :  0.98453419862814&#34;
[1] &#34;Mean Cluster to Cluster Distance      :  0.00206193074501161&#34;
[1] &#34;&#34;
[1] &#34;Run                                   :  5&#34;
[1] &#34;Rand Index (Cluster Similarity)       :  0.543519018344705&#34;
[1] &#34;Mean Cluster to Cluster Distance      :  7.71738488093683&#34;
[1] &#34;&#34;
[1] &#34;Run                                   :  6&#34;
[1] &#34;Rand Index (Cluster Similarity)       :  0.987864916938343&#34;
[1] &#34;Mean Cluster to Cluster Distance      :  0.00119873728593507&#34;
[1] &#34;&#34;
[1] &#34;Run                                   :  7&#34;
[1] &#34;Rand Index (Cluster Similarity)       :  0.985213332884012&#34;
[1] &#34;Mean Cluster to Cluster Distance      :  0.000980403030227557&#34;
[1] &#34;&#34;
[1] &#34;Run                                   :  8&#34;
[1] &#34;Rand Index (Cluster Similarity)       :  0.989991857335321&#34;
[1] &#34;Mean Cluster to Cluster Distance      :  0.000989368363884431&#34;
[1] &#34;&#34;
[1] &#34;Run                                   :  9&#34;
[1] &#34;Rand Index (Cluster Similarity)       :  0.989991857335321&#34;
[1] &#34;Mean Cluster to Cluster Distance      :  0.000713881570771952&#34;
[1] &#34;&#34;
[1] &#34;Run                                   :  10&#34;
[1] &#34;Rand Index (Cluster Similarity)       :  0.543250318710281&#34;
[1] &#34;Mean Cluster to Cluster Distance      :  7.10868911808337&#34;
[1] &#34;&#34;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So now we have several runs of our segmentation on different samples of the dataset and we found that the majority of the time we get 'similar segments'. What do I mean by 'similar'?</p>
<p>First, let's look at two runs that have small cluster to cluster distance. In the tables below we shows the clusters for our initial segmentation and run 3. We see that the two tables are quite similar if we compare each cell. We can also visualize this table with a heatmap, coloring high values with Blue and low with Red. Looking at values this way, Run 3 and the Initial Segmentation have very similar patterns and are nearly identical.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Print Results</span>
<span class="kp">print</span><span class="p">(</span><span class="s">&quot;Our Initial Segmentation&quot;</span><span class="p">)</span>
outputraw<span class="p">[</span>outputraw<span class="o">$</span>run <span class="o">==</span> <span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="kp">ncol</span><span class="p">(</span>outputraw<span class="p">)</span><span class="m">-2</span><span class="p">)]</span>
<span class="kp">print</span><span class="p">(</span><span class="s">&quot;Our Results from Run 3&quot;</span><span class="p">)</span>
outputraw<span class="p">[</span>outputraw<span class="o">$</span>run <span class="o">==</span> <span class="m">3</span><span class="p">,</span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="kp">ncol</span><span class="p">(</span>outputraw<span class="p">)</span><span class="m">-2</span><span class="p">)]</span>

<span class="c1">#Plot Results</span>
plot1<span class="o">&lt;-</span>heatmap.2<span class="p">(</span><span class="kp">as.matrix</span><span class="p">(</span>outputraw<span class="p">[</span>outputraw<span class="o">$</span>run <span class="o">==</span> <span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="kp">ncol</span><span class="p">(</span>outputraw<span class="p">)</span><span class="m">-2</span><span class="p">)]),</span>scale <span class="o">=</span> <span class="s">&quot;column&quot;</span><span class="p">,</span>notecol <span class="o">=</span> <span class="s">&quot;black&quot;</span><span class="p">,</span>Rowv <span class="o">=</span> <span class="s">&quot;False&quot;</span><span class="p">,</span>Colv <span class="o">=</span> <span class="s">&quot;False&quot;</span>
                 <span class="p">,</span>main <span class="o">=</span> <span class="s">&quot;Initial Segmentation&quot;</span><span class="p">,</span>col <span class="o">=</span> mypalette<span class="p">,</span>key.xlab <span class="o">=</span> <span class="s">&quot;Low (Red) to High (Blue)&quot;</span><span class="p">,</span> trace <span class="o">=</span> <span class="s">&quot;none&quot;</span><span class="p">,</span>density.info <span class="o">=</span> <span class="s">&quot;none&quot;</span><span class="p">)</span>
plot2<span class="o">&lt;-</span>heatmap.2<span class="p">(</span><span class="kp">as.matrix</span><span class="p">(</span>outputraw<span class="p">[</span>outputraw<span class="o">$</span>run <span class="o">==</span> <span class="m">3</span><span class="p">,</span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="kp">ncol</span><span class="p">(</span>outputraw<span class="p">)</span><span class="m">-2</span><span class="p">)]),</span>scale <span class="o">=</span> <span class="s">&quot;column&quot;</span><span class="p">,</span>notecol<span class="o">=</span><span class="s">&quot;black&quot;</span><span class="p">,</span>Rowv<span class="o">=</span><span class="s">&quot;False&quot;</span><span class="p">,</span>Colv<span class="o">=</span><span class="s">&quot;False&quot;</span>
                 <span class="p">,</span>main <span class="o">=</span> <span class="s">&quot;Run 3&quot;</span><span class="p">,</span>col <span class="o">=</span> mypalette<span class="p">,</span>key.xlab <span class="o">=</span> <span class="s">&quot;Low (Red) to High (Blue)&quot;</span><span class="p">,</span>trace <span class="o">=</span> <span class="s">&quot;none&quot;</span><span class="p">,</span>density.info <span class="o">=</span> <span class="s">&quot;none&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>[1] &#34;Our Initial Segmentation&#34;
</pre>
</div>
</div>

<div class="output_area">

<div class="output_html rendered_html output_subarea output_execute_result">
<table>
<thead><tr><th></th><th scope=col>WAGP</th><th scope=col>WKHP</th><th scope=col>SCHL</th><th scope=col>OIP</th><th scope=col>INTP</th><th scope=col>AGEP</th></tr></thead>
<tbody>
	<tr><th scope=row>1</th><td>27611.72</td><td>35.08066</td><td>16.58214</td><td>31.03547</td><td>513.4261</td><td>55.20372</td></tr>
	<tr><th scope=row>2</th><td>32600.02</td><td>37.7873</td><td>18.60336</td><td>10074.61</td><td>1199.137</td><td>44.77075</td></tr>
	<tr><th scope=row>3</th><td>25622.85</td><td>36.4214</td><td>18.65289</td><td>31.73979</td><td>76.9764</td><td>30.57355</td></tr>
	<tr><th scope=row>4</th><td>100713.3</td><td>47.1395</td><td>20.89377</td><td>16.80845</td><td>4397.971</td><td>48.54713</td></tr>
</tbody>
</table>

</div>

</div>

<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>[1] &#34;Our Results from Run 3&#34;
</pre>
</div>
</div>

<div class="output_area">

<div class="output_html rendered_html output_subarea output_execute_result">
<table>
<thead><tr><th></th><th scope=col>WAGP</th><th scope=col>WKHP</th><th scope=col>SCHL</th><th scope=col>OIP</th><th scope=col>INTP</th><th scope=col>AGEP</th></tr></thead>
<tbody>
	<tr><th scope=row>22</th><td>27596.09</td><td>35.31116</td><td>16.56168</td><td>30.99711</td><td>466.5372</td><td>54.98646</td></tr>
	<tr><th scope=row>42</th><td>31676.05</td><td>37.71996</td><td>18.58777</td><td>10071.87</td><td>859.7223</td><td>45.38584</td></tr>
	<tr><th scope=row>32</th><td>25373.68</td><td>36.17056</td><td>18.70392</td><td>31.06117</td><td>92.61854</td><td>30.48965</td></tr>
	<tr><th scope=row>12</th><td>101711.6</td><td>47.28349</td><td>20.87861</td><td>18.18128</td><td>4488.324</td><td>48.43956</td></tr>
</tbody>
</table>

</div>

</div>

<div class="output_area">


<div class="output_png output_subarea ">
<img src="data:image/png;base64,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"
>
</div>

</div>

<div class="output_area">


<div class="output_png output_subarea ">
<img src="data:image/png;base64,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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can also look at the raw difference between these clusterings. The largest difference is in WKHP (Working Hours Per Week) in segment 2 at 2% of the standard deviation of WKHP.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Normalizing the Variables</span>
m <span class="o">&lt;-</span> <span class="kp">colMeans</span><span class="p">(</span>datprep2<span class="p">)</span>
sd <span class="o">&lt;-</span> <span class="kp">apply</span><span class="p">(</span>datprep2<span class="p">,</span><span class="m">2</span><span class="p">,</span>FUN <span class="o">=</span> sd<span class="p">)</span>
M <span class="o">&lt;-</span> <span class="kp">t</span><span class="p">(</span><span class="kt">matrix</span><span class="p">(</span>m<span class="p">))[</span><span class="kp">rep</span><span class="p">(</span><span class="m">1</span><span class="p">,</span>ksize<span class="p">),]</span>
S <span class="o">&lt;-</span> <span class="kp">t</span><span class="p">(</span><span class="kt">matrix</span><span class="p">(</span>sd<span class="p">))[</span><span class="kp">rep</span><span class="p">(</span><span class="m">1</span><span class="p">,</span>ksize<span class="p">),]</span>

<span class="c1">#Computing the difference</span>
<span class="p">(</span>outputraw<span class="p">[</span>outputraw<span class="o">$</span>run <span class="o">==</span> <span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="kp">ncol</span><span class="p">(</span>outputraw<span class="p">)</span><span class="m">-2</span><span class="p">)]</span><span class="o">-</span>M<span class="p">)</span><span class="o">/</span>S <span class="o">-</span> <span class="p">(</span>outputraw<span class="p">[</span>outputraw<span class="o">$</span>run <span class="o">==</span> <span class="m">3</span><span class="p">,</span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="kp">ncol</span><span class="p">(</span>outputraw<span class="p">)</span><span class="m">-2</span><span class="p">)]</span><span class="o">-</span>M<span class="p">)</span><span class="o">/</span>S
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="output_html rendered_html output_subarea output_execute_result">
<table>
<thead><tr><th></th><th scope=col>WAGP</th><th scope=col>WKHP</th><th scope=col>SCHL</th><th scope=col>OIP</th><th scope=col>INTP</th><th scope=col>AGEP</th></tr></thead>
<tbody>
	<tr><th scope=row>1</th><td>0.0002763829</td><td>-0.01866915</td><td>0.006070284</td><td>1.392182e-05</td><td>0.003407244</td><td>0.01573137</td></tr>
	<tr><th scope=row>2</th><td>0.01634655</td><td>0.005454563</td><td>0.00462637</td><td>0.0009949407</td><td>0.02466403</td><td>-0.04453691</td></tr>
	<tr><th scope=row>3</th><td>0.004408337</td><td>0.02031592</td><td>-0.01514522</td><td>0.0002462934</td><td>-0.001136657</td><td>0.006074798</td></tr>
	<tr><th scope=row>4</th><td>-0.01766085</td><td>-0.0116624</td><td>0.004498052</td><td>-0.0004982402</td><td>-0.00656564</td><td>0.007789398</td></tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Measuring-Cluster-Similarity:-Rand-Index">Measuring Cluster Similarity: Rand Index<a class="anchor-link" href="#Measuring-Cluster-Similarity:-Rand-Index">&#182;</a></h3><p>You may have noticed in the output that cluster similarity was measured in two ways. The first is a simple calculation of cluster to cluster distance between centroids. A more robust method often used to compare clusterings is the Rand Index (<a href="https://en.wikipedia.org/wiki/Rand_index">https://en.wikipedia.org/wiki/Rand_index</a>). For the Rand Index we compare how often two clusterings agree on the labels assigned to a datapoints in the cluster. Now, normally we would have a problem since cluster 1 in run 1 may not be the same are cluster 1 in run 2, but you'll recall that we reordered our labels using minimum distance in order to match our initial segmentation. In Luxburg 2010 the Rand Index is typically the maximum taken over ALL permutations of the index, but we'll use our short cut for now so we don't have to permute over all K.</p>
<p>As for properties of the Rand Index, if two clusterings completely agree on labels then the Rand Index is 1. If the clusterings complete disagree the Rand Index will be 0. In reality Rand Index should never drop below 0.5 since this value of a clustering compared against completely random labels.</p>
<p>We use the holdout set defined earlier in 'Our Method for Today' (point 1) in order to evaluate the Rand Index.</p>
<p>Let's look at some examples. Here we see segmentations agree when we have a low cluster to cluster (Euclidean) distance and a high Rand Index:</p>
<p>[1] "Run                                   :  3"<br>
[1] "Rand Index (Cluster Similarity)       :  0.987185074113396"<br>
[1] "Mean Cluster to Cluster Distance      :  0.00103289705216875"</p>
<p>Conversely, we can also look at a segmentation that is completely different from what we started with. Here we see that not only is the Rand Index low, but the distance between our Initial Segmentation and our new run is massive.</p>
<p>[1] "Run                                   :  5"<br>
[1] "Rand Index (Cluster Similarity)       :  0.543519018344705"<br>
[1] "Mean Cluster to Cluster Distance      :  7.71738488093683"</p>
<p>Let's visualize this as we did previously:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-r"><pre><span></span><span class="kp">print</span><span class="p">(</span><span class="s">&quot;Our Initial Segmentation&quot;</span><span class="p">)</span>
<span class="kp">as.matrix</span><span class="p">(</span>outputraw<span class="p">[</span>outputraw<span class="o">$</span>run<span class="o">==</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="kp">ncol</span><span class="p">(</span>outputraw<span class="p">)</span><span class="m">-2</span><span class="p">)])</span>
<span class="kp">print</span><span class="p">(</span><span class="s">&quot;Our Results from Run 5&quot;</span><span class="p">)</span>
<span class="kp">as.matrix</span><span class="p">(</span>outputraw<span class="p">[</span>outputraw<span class="o">$</span>run<span class="o">==</span><span class="m">5</span><span class="p">,</span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="kp">ncol</span><span class="p">(</span>outputraw<span class="p">)</span><span class="m">-2</span><span class="p">)])</span>

heatmap.2<span class="p">(</span><span class="kp">as.matrix</span><span class="p">(</span>outputraw<span class="p">[</span>outputraw<span class="o">$</span>run<span class="o">==</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="kp">ncol</span><span class="p">(</span>outputraw<span class="p">)</span><span class="m">-2</span><span class="p">)]),</span>scale <span class="o">=</span> <span class="s">&quot;column&quot;</span><span class="p">,</span>notecol <span class="o">=</span> <span class="s">&quot;black&quot;</span><span class="p">,</span>Rowv <span class="o">=</span> <span class="s">&quot;False&quot;</span><span class="p">,</span>Colv <span class="o">=</span> <span class="s">&quot;False&quot;</span>
                 <span class="p">,</span>main <span class="o">=</span> <span class="s">&quot;Initial Segmentation&quot;</span><span class="p">,</span>col <span class="o">=</span> mypalette<span class="p">,</span>key.xlab <span class="o">=</span> <span class="s">&quot;Low (Red) to High (Blue)&quot;</span><span class="p">,</span> trace <span class="o">=</span> <span class="s">&quot;none&quot;</span><span class="p">,</span>density.info <span class="o">=</span> <span class="s">&quot;none&quot;</span><span class="p">)</span>

heatmap.2<span class="p">(</span><span class="kp">as.matrix</span><span class="p">(</span>outputraw<span class="p">[</span>outputraw<span class="o">$</span>run<span class="o">==</span><span class="m">5</span><span class="p">,</span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="kp">ncol</span><span class="p">(</span>outputraw<span class="p">)</span><span class="m">-2</span><span class="p">)]),</span>scale <span class="o">=</span> <span class="s">&quot;column&quot;</span><span class="p">,</span>notecol<span class="o">=</span><span class="s">&quot;black&quot;</span><span class="p">,</span>Rowv<span class="o">=</span><span class="s">&quot;False&quot;</span><span class="p">,</span>Colv<span class="o">=</span><span class="s">&quot;False&quot;</span>
                 <span class="p">,</span>main <span class="o">=</span> <span class="s">&quot;Run 5&quot;</span><span class="p">,</span>col <span class="o">=</span> mypalette<span class="p">,</span>key.xlab <span class="o">=</span> <span class="s">&quot;Low (Red) to High (Blue)&quot;</span><span class="p">,</span>trace <span class="o">=</span> <span class="s">&quot;none&quot;</span><span class="p">,</span>density.info <span class="o">=</span> <span class="s">&quot;none&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>[1] &#34;Our Initial Segmentation&#34;
</pre>
</div>
</div>

<div class="output_area">

<div class="output_html rendered_html output_subarea output_execute_result">
<table>
<thead><tr><th></th><th scope=col>WAGP</th><th scope=col>WKHP</th><th scope=col>SCHL</th><th scope=col>OIP</th><th scope=col>INTP</th><th scope=col>AGEP</th></tr></thead>
<tbody>
	<tr><th scope=row>1</th><td>27611.71635</td><td>   35.08066</td><td>   16.58214</td><td>   31.03547</td><td>  513.42614</td><td>   55.20372</td></tr>
	<tr><th scope=row>2</th><td>32600.01628</td><td>   37.78730</td><td>   18.60336</td><td>10074.60662</td><td> 1199.13728</td><td>   44.77075</td></tr>
	<tr><th scope=row>3</th><td>25622.85121</td><td>   36.42140</td><td>   18.65289</td><td>   31.73979</td><td>   76.97640</td><td>   30.57355</td></tr>
	<tr><th scope=row>4</th><td>100713.31362</td><td>    47.13950</td><td>    20.89377</td><td>    16.80845</td><td>  4397.97057</td><td>    48.54713</td></tr>
</tbody>
</table>

</div>

</div>

<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>[1] &#34;Our Results from Run 5&#34;
</pre>
</div>
</div>

<div class="output_area">

<div class="output_html rendered_html output_subarea output_execute_result">
<table>
<thead><tr><th></th><th scope=col>WAGP</th><th scope=col>WKHP</th><th scope=col>SCHL</th><th scope=col>OIP</th><th scope=col>INTP</th><th scope=col>AGEP</th></tr></thead>
<tbody>
	<tr><th scope=row>24</th><td>32316.34217</td><td>   41.43658</td><td>   15.70461</td><td> 1044.78360</td><td>  170.26842</td><td>   51.12773</td></tr>
	<tr><th scope=row>14</th><td>32005.57642</td><td>   40.55994</td><td>   19.19728</td><td>   50.62555</td><td>   60.22878</td><td>   31.12786</td></tr>
	<tr><th scope=row>34</th><td>11501.81730</td><td>   18.91315</td><td>   18.81042</td><td>  396.90925</td><td> 1413.28470</td><td>   47.54802</td></tr>
	<tr><th scope=row>44</th><td>104423.95262</td><td>    46.59078</td><td>    20.99859</td><td>   131.00067</td><td>  4751.29578</td><td>    50.64040</td></tr>
</tbody>
</table>

</div>

</div>

<div class="output_area">


<div class="output_png output_subarea ">
<img src="data:image/png;base64,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"
>
</div>

</div>

<div class="output_area">


<div class="output_png output_subarea ">
<img src="data:image/png;base64,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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To highlight the differences, let's again look at the difference between the initial segmentation and run 5:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-r"><pre><span></span><span class="p">(</span>outputraw<span class="p">[</span>outputraw<span class="o">$</span>run <span class="o">==</span> <span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="kp">ncol</span><span class="p">(</span>outputraw<span class="p">)</span><span class="m">-2</span><span class="p">)]</span><span class="o">-</span>M<span class="p">)</span><span class="o">/</span>S <span class="o">-</span> <span class="p">(</span>outputraw<span class="p">[</span>outputraw<span class="o">$</span>run <span class="o">==</span> <span class="m">5</span><span class="p">,</span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="kp">ncol</span><span class="p">(</span>outputraw<span class="p">)</span><span class="m">-2</span><span class="p">)]</span><span class="o">-</span>M<span class="p">)</span><span class="o">/</span>S
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="output_html rendered_html output_subarea output_execute_result">
<table>
<thead><tr><th></th><th scope=col>WAGP</th><th scope=col>WKHP</th><th scope=col>SCHL</th><th scope=col>OIP</th><th scope=col>INTP</th><th scope=col>AGEP</th></tr></thead>
<tbody>
	<tr><th scope=row>1</th><td>-0.08323318</td><td>-0.5147928</td><td>0.2604136</td><td>-0.3679191</td><td>0.024936</td><td>0.295132</td></tr>
	<tr><th scope=row>2</th><td>0.0105167</td><td>-0.2245678</td><td>-0.1762496</td><td>3.637999</td><td>0.08276025</td><td>0.987848</td></tr>
	<tr><th scope=row>3</th><td>0.2498262</td><td>1.418066</td><td>-0.04674824</td><td>-0.1325308</td><td>-0.09710456</td><td>-1.229079</td></tr>
	<tr><th scope=row>4</th><td>-0.06564779</td><td>0.04444289</td><td>-0.03110575</td><td>-0.04144373</td><td>-0.02567483</td><td>-0.1515682</td></tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So now we're looking at a completely different segmentation. We see that Run 4 has very different attributes for WKHP, OIP and AGEP compared to the initial clustering especially in clusters 2 and 3. We can say that when see a particularly high cluster to cluster distance or low Rand Index between clusterings we end up with a different interpretation of the data. This is what we wish to avoid. Let's look at this in another way.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Visualizing-Error">Visualizing Error<a class="anchor-link" href="#Visualizing-Error">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We have 10 Runs of Segmentation (Plus our Initial Segmentation). Let's plot the values for WAGP for every segmentation. What we'll see below is the value of WAGP for every 4 segments in our 10 runs. The first segment is colored red. Over 10 runs we see that there's a small amount of variation in WAGP for segments 1 and 4. In segment 3 (teal) however we see two vastly different values for WAGP in certain runs (under 15k and over 70k in runs 2 and 5 respectively), diverging from what we would normally expect (25k).</p>
<p>If we weren't looking at multiple runs we would never see this and might assume we'd always get the same clustering! Additionally this suggests that perhaps four clusters is not the best way to express this data...</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-r"><pre><span></span>output2<span class="o">&lt;-</span>outputraw<span class="p">[</span><span class="kp">order</span><span class="p">(</span>outputraw<span class="o">$</span>segment<span class="p">),]</span>
output2<span class="o">$</span>segment <span class="o">&lt;-</span> <span class="kp">as.factor</span><span class="p">(</span>output2<span class="o">$</span>segment<span class="p">)</span>
output2<span class="o">$</span>index<span class="o">&lt;-</span><span class="m">1</span><span class="o">:</span><span class="kp">nrow</span><span class="p">(</span>output2<span class="p">)</span>

ggplot<span class="p">(</span>output2<span class="p">,</span> aes<span class="p">(</span>x <span class="o">=</span> index<span class="p">,</span> y <span class="o">=</span> WAGP<span class="p">,</span> colour <span class="o">=</span> segment<span class="p">))</span> <span class="o">+</span> xlab<span class="p">(</span><span class="s">&quot;Cluster Run Index&quot;</span><span class="p">)</span> <span class="o">+</span> 
  geom_point<span class="p">(</span>size <span class="o">=</span> <span class="m">3</span><span class="p">)</span> <span class="o">+</span> ggtitle<span class="p">(</span><span class="s">&quot;Plot of WAGP for Different Clusters in Different Runs&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">


<div class="output_png output_subarea ">
<img src="data:image/png;base64,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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="What-Does-Stability-Look-Like?">What Does Stability Look Like?<a class="anchor-link" href="#What-Does-Stability-Look-Like?">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With the methods above as a framework we can step through different clustering sizes and see if we arrive at more stable segmentations. We can also assess stability by using the mean Rand Index for each run (excluding the first). In our code we express this as 'randResults'. Unfortunately an old problem rears its ugly here. In this method we started with an initial segmentation (run 1) to compare to each subsequent segmentation. In a stable regime we're more than likely to land on the 'stable' segmentation on our first time, but this is always not the case. When we land on a bad segment we will need to reinitialize and try again. Hoping our first segmentation is a good one.</p>
<p>Suffice to say, there are better methods for getting around problems of initialization (discussed in detail in page 9 of Luxburg 2010). For now we'll leave that to a future blog post and say that working through this dataset we found that a segmentation with 9 clusters is quite stable.</p>
<p>Below we'll run the same code as in our 'Stability Testing' section, however we'll increase our number of clusters (K) to 9.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-r"><pre><span></span><span class="c1">#Turn Off Warnings</span>
<span class="kp">options</span><span class="p">(</span>warn<span class="o">=</span><span class="m">-1</span><span class="p">)</span>

ksize<span class="o">&lt;-</span><span class="m">9</span>
bootstraps<span class="o">&lt;-</span><span class="m">10</span>

assignmentResults<span class="o">&lt;-</span><span class="kt">data.frame</span><span class="p">(</span><span class="kt">matrix</span><span class="p">(,</span>nrow <span class="o">=</span> bootstraps<span class="p">,</span> ncol <span class="o">=</span> <span class="m">1000</span><span class="p">))</span>
randResults<span class="o">&lt;-</span><span class="kt">c</span><span class="p">()</span>


<span class="kr">for</span> <span class="p">(</span>iclustering <span class="kr">in</span> <span class="m">1</span><span class="o">:</span>bootstraps<span class="p">)</span> <span class="p">{</span>
  
  
  samplingIntegers<span class="o">&lt;-</span><span class="kp">sample</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="kp">nrow</span><span class="p">(</span>train<span class="p">),</span><span class="m">100000</span><span class="p">)</span>
  
  datprep7<span class="o">&lt;-</span>train<span class="p">[</span>samplingIntegers<span class="p">,]</span>
  datprepRaw<span class="o">&lt;-</span>trainRaw<span class="p">[</span>samplingIntegers<span class="p">,]</span>
  
  <span class="c1">##Initialization Method For Kmeans Described in Dasgupta and Schulman (2007)</span>
  
  initialKmeans <span class="o">&lt;-</span> kmeans<span class="p">(</span>datprep7<span class="p">,</span> <span class="kp">ceiling</span><span class="p">(</span>ksize<span class="o">*</span><span class="kp">log</span><span class="p">(</span>ksize<span class="p">)),</span>iter.max <span class="o">=</span> <span class="m">1</span><span class="p">)</span>
  validCenters <span class="o">&lt;-</span> initialKmeans<span class="o">$</span>size<span class="o">/</span><span class="kp">nrow</span><span class="p">(</span>datprep7<span class="p">)</span><span class="o">*</span><span class="kp">ceiling</span><span class="p">(</span>ksize<span class="o">*</span><span class="kp">log</span><span class="p">(</span>ksize<span class="p">))</span> <span class="o">&gt;</span> <span class="m">1</span><span class="o">/</span><span class="m">2</span>
  centersNoOutliers <span class="o">&lt;-</span> initialKmeans<span class="o">$</span>centers<span class="p">[</span>validCenters<span class="p">,]</span>
  
  
<span class="kr">if</span> <span class="p">(</span><span class="kp">sum</span><span class="p">(</span>validCenters<span class="p">)</span> <span class="o">&gt;</span> ksize<span class="p">)</span> <span class="p">{</span>
  
  nextCenter <span class="o">&lt;-</span> centersNoOutliers<span class="p">[</span><span class="m">1</span><span class="p">,]</span> <span class="c1">#Start with a Random Center</span>
  initialCenters <span class="o">&lt;-</span> <span class="kt">data.frame</span><span class="p">(</span><span class="kp">t</span><span class="p">(</span>nextCenter<span class="p">))</span>
  centersConsidered <span class="o">&lt;-</span> <span class="m">2</span><span class="o">:</span><span class="kp">nrow</span><span class="p">(</span>centersNoOutliers<span class="p">)</span> <span class="c1">#Keep track of the centers that can still be added</span>
  
  <span class="kr">for</span><span class="p">(</span>i <span class="kr">in</span> <span class="m">1</span><span class="o">:</span><span class="p">(</span>ksize<span class="m">-1</span><span class="p">)){</span>
    
    k2<span class="o">&lt;-</span><span class="kt">matrix</span><span class="p">(,</span>ncol <span class="o">=</span> <span class="kp">nrow</span><span class="p">(</span>centersNoOutliers<span class="p">),</span>nrow <span class="o">=</span> i<span class="p">)</span>
    
    <span class="kr">for</span><span class="p">(</span>k <span class="kr">in</span> <span class="m">1</span><span class="o">:</span>i<span class="p">)</span> <span class="p">{</span>
    
    <span class="kr">for</span><span class="p">(</span> j <span class="kr">in</span> <span class="m">1</span><span class="o">:</span><span class="kp">nrow</span><span class="p">(</span>centersNoOutliers<span class="p">))</span> <span class="p">{</span>
      k2<span class="p">[</span>k<span class="p">,</span>j<span class="p">]</span><span class="o">&lt;-</span><span class="kp">sum</span><span class="p">((</span>centersNoOutliers<span class="p">[</span>j<span class="p">,]</span><span class="o">-</span>initialCenters<span class="p">[</span>k<span class="p">,])</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
       <span class="p">}</span>
    <span class="p">}</span> <span class="c1">#Create a Distance Matrix between the centers currently selected and all centers</span>
    
    <span class="kr">if</span><span class="p">(</span>i <span class="o">==</span> <span class="m">1</span><span class="p">){</span>
      k3 <span class="o">&lt;-</span> k2<span class="p">}</span><span class="kp">else</span><span class="p">{</span>
    clusterWithMaxMinDistance <span class="o">&lt;-</span> <span class="kp">which.max</span><span class="p">(</span><span class="kp">apply</span><span class="p">(</span>k2<span class="p">[,</span>centersConsidered<span class="p">],</span><span class="m">1</span><span class="p">,</span>FUN<span class="o">=</span><span class="kp">min</span><span class="p">))</span>
    k3 <span class="o">&lt;-</span> k2<span class="p">[</span>clusterWithMaxMinDistance<span class="p">,]</span>
    <span class="p">}</span> <span class="c1">#Calculating relevant distances to find the cluster that maximizes the minimum distance to the centers already selected.</span>
  
    nextCenter <span class="o">&lt;-</span> centersNoOutliers<span class="p">[</span>centersConsidered<span class="p">[</span><span class="kp">which.max</span><span class="p">(</span> k3<span class="p">[</span>centersConsidered<span class="p">])],]</span> 
      <span class="c1">#Select the center which maximizes the minimum distance to one of the centers already selected</span>
    centersConsidered <span class="o">&lt;-</span> centersConsidered<span class="p">[</span><span class="o">-</span><span class="kp">which.max</span><span class="p">(</span> k3<span class="p">[</span>centersConsidered<span class="p">])]</span>
      <span class="c1">#One selected we have to remove it from the centers that are still up for selection</span>
    initialCenters <span class="o">&lt;-</span> <span class="kp">rbind</span><span class="p">(</span>initialCenters<span class="p">,</span>nextCenter<span class="p">)</span>
      <span class="c1">#And finally add the new center to the list of initialization centers for K-means.</span>
    
  <span class="p">}</span>
  
<span class="p">}</span><span class="kr">else</span> <span class="p">{</span>initialCenters <span class="o">&lt;-</span> centersNoOutliers <span class="p">}</span>
  
  
  
  
  <span class="c1">#Now we do Kmeans</span>
  
  PCAKmeans <span class="o">&lt;-</span> kcca<span class="p">(</span>datprep7<span class="p">,</span> k <span class="o">=</span> <span class="kp">as.matrix</span><span class="p">(</span>initialCenters<span class="p">),</span> kccaFamily<span class="p">(</span><span class="s">&quot;kmeans&quot;</span><span class="p">),</span>simple<span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
  
  
  clustersize<span class="o">&lt;-</span>PCAKmeans<span class="o">@</span>clusinfo<span class="o">$</span>size<span class="o">/</span><span class="kp">sum</span><span class="p">(</span>PCAKmeans<span class="o">@</span>clusinfo<span class="o">$</span>size<span class="p">)</span>
  testcluster<span class="o">&lt;-</span>aggregate<span class="p">(</span>datprep7<span class="p">,</span>by<span class="o">=</span><span class="kt">list</span><span class="p">(</span>PCAKmeans<span class="o">@</span>cluster<span class="p">),</span>FUN <span class="o">=</span> <span class="kp">mean</span><span class="p">)</span>
  testcluster<span class="o">&lt;-</span>testcluster<span class="p">[,</span><span class="m">2</span><span class="o">:</span><span class="kp">ncol</span><span class="p">(</span>testcluster<span class="p">)]</span>
  testClusterRealValues <span class="o">&lt;-</span> aggregate<span class="p">(</span>datprepRaw<span class="p">,</span>by<span class="o">=</span><span class="kt">list</span><span class="p">(</span>PCAKmeans<span class="o">@</span>cluster<span class="p">),</span>FUN <span class="o">=</span> <span class="kp">mean</span><span class="p">)</span>
  
  
  <span class="c1">#Reorder Groups to Match First Clustering</span>
  <span class="kr">if</span><span class="p">(</span>iclustering<span class="o">==</span><span class="m">1</span><span class="p">)</span> <span class="p">{</span>
    truecluster<span class="o">&lt;-</span>testcluster
    initialSegmentation<span class="o">&lt;-</span>PCAKmeans
  <span class="p">}</span> <span class="kr">else</span> <span class="p">{</span>
    
    clustersconsidered<span class="o">&lt;-</span><span class="m">1</span><span class="o">:</span>ksize
    clusterscore2<span class="o">&lt;-</span> <span class="m">1</span><span class="o">:</span>ksize
    cluster2clusterdistance<span class="o">&lt;-</span><span class="m">0</span>
    
    
    <span class="kr">for</span> <span class="p">(</span> i <span class="kr">in</span> <span class="m">1</span><span class="o">:</span><span class="kp">nrow</span><span class="p">(</span>truecluster<span class="p">))</span> <span class="p">{</span>
      
      
      k2<span class="o">&lt;-</span><span class="kt">c</span><span class="p">()</span>
      <span class="kr">for</span><span class="p">(</span> j <span class="kr">in</span> <span class="m">1</span><span class="o">:</span><span class="kp">nrow</span><span class="p">(</span>testcluster<span class="p">))</span> <span class="p">{</span>
        k2<span class="p">[</span>j<span class="p">]</span><span class="o">&lt;-</span><span class="kp">sum</span><span class="p">((</span>testcluster<span class="p">[</span>j<span class="p">,]</span><span class="o">-</span>truecluster<span class="p">[</span>i<span class="p">,])</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
        
      <span class="p">}</span>
      clusterscore2<span class="p">[</span>i<span class="p">]</span><span class="o">&lt;-</span>clustersconsidered<span class="p">[</span><span class="kp">which.min</span><span class="p">(</span> k2<span class="p">[</span>clustersconsidered<span class="p">])]</span>
      cluster2clusterdistance<span class="o">&lt;-</span>cluster2clusterdistance <span class="o">+</span> <span class="kp">min</span><span class="p">(</span> k2<span class="p">[</span>clustersconsidered<span class="p">])</span>
      clustersconsidered<span class="o">&lt;-</span>clustersconsidered<span class="p">[</span><span class="o">-</span><span class="kp">which.min</span><span class="p">(</span>k2<span class="p">[</span>clustersconsidered<span class="p">])]</span>
      
    <span class="p">}</span>
  <span class="p">}</span> 
  
  <span class="c1">#If the first run create a table</span>
  
  <span class="kr">if</span> <span class="p">(</span>iclustering<span class="o">==</span><span class="m">1</span><span class="p">)</span> <span class="p">{</span>
    output<span class="o">&lt;-</span>testcluster
    output<span class="o">$</span>segment<span class="o">&lt;-</span><span class="m">1</span><span class="o">:</span>ksize
    output<span class="o">$</span>run<span class="o">&lt;-</span>iclustering
 
    outputraw <span class="o">&lt;-</span>   testClusterRealValues<span class="p">[,</span><span class="m">2</span><span class="o">:</span><span class="kp">ncol</span><span class="p">(</span>testClusterRealValues<span class="p">)]</span>
    outputraw<span class="o">$</span>segment<span class="o">&lt;-</span><span class="m">1</span><span class="o">:</span>ksize
    outputraw<span class="o">$</span>run<span class="o">&lt;-</span>iclustering
    
    <span class="c1">#Labeling the holdout dataset with the model and using it to calculate the Rand Index</span>
    labelsInitial<span class="o">&lt;-</span>predict<span class="p">(</span>initialSegmentation<span class="p">,</span>holdout<span class="p">)</span>
    assignmentResults<span class="p">[</span>iclustering<span class="p">,]</span><span class="o">&lt;-</span>labelsInitial<span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">]</span>
    randResults<span class="p">[</span>iclustering<span class="p">]</span> <span class="o">&lt;-</span> <span class="m">1</span>
    
    <span class="kp">print</span><span class="p">(</span> <span class="kp">paste</span><span class="p">(</span><span class="kt">c</span><span class="p">(</span><span class="s">&quot;Run                                   : &quot;</span><span class="p">,</span>iclustering<span class="p">),</span>collapse<span class="o">=</span><span class="s">&quot; &quot;</span> <span class="p">))</span>
    <span class="kp">print</span><span class="p">(</span> <span class="s">&quot;&quot;</span> <span class="p">)</span>
    
    
  <span class="p">}</span> <span class="kr">else</span> <span class="p">{</span>
      
  <span class="c1">#If any other run append to the table</span>
      
    new<span class="o">&lt;-</span>testcluster<span class="p">[</span>clusterscore2<span class="p">,]</span>
    new<span class="o">$</span>segment<span class="o">&lt;-</span><span class="m">1</span><span class="o">:</span>ksize
    new<span class="o">$</span>run<span class="o">&lt;-</span>iclustering
    output<span class="o">&lt;-</span><span class="kp">rbind</span><span class="p">(</span>output<span class="p">,</span>new<span class="p">)</span>

    rawCenters<span class="o">&lt;-</span>testClusterRealValues<span class="p">[</span>clusterscore2<span class="p">,]</span>
    rawCenters<span class="o">$</span>segment<span class="o">&lt;-</span><span class="m">1</span><span class="o">:</span>ksize
    rawCenters<span class="o">$</span>run<span class="o">&lt;-</span>iclustering
    outputraw<span class="o">&lt;-</span><span class="kp">rbind</span><span class="p">(</span>outputraw<span class="p">,</span>rawCenters<span class="p">[,</span><span class="m">2</span><span class="o">:</span><span class="kp">ncol</span><span class="p">(</span>rawCenters<span class="p">)])</span>
    
    <span class="c1">#Labeling the holdout dataset with the model and using it to calculate the Rand Index</span>
    labelsTest<span class="o">&lt;-</span>predict<span class="p">(</span>PCAKmeans<span class="p">,</span>holdout<span class="p">)</span>
    labelsTest2<span class="o">&lt;-</span><span class="kp">factor</span><span class="p">(</span>labelsTest<span class="p">)</span>
    <span class="kp">levels</span><span class="p">(</span>labelsTest2<span class="p">)</span><span class="o">&lt;-</span><span class="kp">order</span><span class="p">(</span>clusterscore2<span class="p">)</span>
    stabilityMeasure<span class="o">&lt;-</span>randIndex<span class="p">(</span>labelsInitial<span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">],</span>labelsTest2<span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">])</span>
    assignmentResults<span class="p">[</span>iclustering<span class="p">,]</span><span class="o">&lt;-</span>labelsTest2<span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">]</span>
    randResults<span class="p">[</span>iclustering<span class="p">]</span> <span class="o">&lt;-</span> stabilityMeasure
    
    
    <span class="kp">print</span><span class="p">(</span> <span class="kp">paste</span><span class="p">(</span><span class="kt">c</span><span class="p">(</span><span class="s">&quot;Run                                   : &quot;</span><span class="p">,</span>iclustering<span class="p">),</span>collapse<span class="o">=</span><span class="s">&quot; &quot;</span> <span class="p">))</span>
    <span class="kp">print</span><span class="p">(</span> <span class="kp">paste</span><span class="p">(</span><span class="kt">c</span><span class="p">(</span><span class="s">&quot;Rand Index (Cluster Similarity)       : &quot;</span><span class="p">,</span>stabilityMeasure<span class="p">),</span>collapse<span class="o">=</span><span class="s">&quot; &quot;</span> <span class="p">))</span>
    <span class="kp">print</span><span class="p">(</span> <span class="kp">paste</span><span class="p">(</span><span class="kt">c</span><span class="p">(</span><span class="s">&quot;Mean Cluster to Cluster Distance      : &quot;</span><span class="p">,</span>cluster2clusterdistance<span class="o">/</span>ksize<span class="p">),</span>collapse<span class="o">=</span><span class="s">&quot; &quot;</span> <span class="p">))</span>
    <span class="kp">print</span><span class="p">(</span> <span class="s">&quot;&quot;</span> <span class="p">)</span>
    
    
  <span class="p">}</span>
<span class="p">}</span>

<span class="c1">#Turn On Warnings</span>
<span class="kp">options</span><span class="p">(</span>warn<span class="o">=</span><span class="m">0</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>[1] &#34;Run                                   :  1&#34;
[1] &#34;&#34;
[1] &#34;Run                                   :  2&#34;
[1] &#34;Rand Index (Cluster Similarity)       :  0.986049054884462&#34;
[1] &#34;Mean Cluster to Cluster Distance      :  0.00269780812889357&#34;
[1] &#34;&#34;
[1] &#34;Run                                   :  3&#34;
[1] &#34;Rand Index (Cluster Similarity)       :  0.988947565909515&#34;
[1] &#34;Mean Cluster to Cluster Distance      :  0.00311277776394503&#34;
[1] &#34;&#34;
[1] &#34;Run                                   :  4&#34;
[1] &#34;Rand Index (Cluster Similarity)       :  0.972996345261564&#34;
[1] &#34;Mean Cluster to Cluster Distance      :  0.00257998568441758&#34;
[1] &#34;&#34;
[1] &#34;Run                                   :  5&#34;
[1] &#34;Rand Index (Cluster Similarity)       :  0.989686398500866&#34;
[1] &#34;Mean Cluster to Cluster Distance      :  0.00169287432254583&#34;
[1] &#34;&#34;
[1] &#34;Run                                   :  6&#34;
[1] &#34;Rand Index (Cluster Similarity)       :  0.97134062698434&#34;
[1] &#34;Mean Cluster to Cluster Distance      :  0.00162410785864138&#34;
[1] &#34;&#34;
[1] &#34;Run                                   :  7&#34;
[1] &#34;Rand Index (Cluster Similarity)       :  0.994805512037336&#34;
[1] &#34;Mean Cluster to Cluster Distance      :  0.0022019464336647&#34;
[1] &#34;&#34;
[1] &#34;Run                                   :  8&#34;
[1] &#34;Rand Index (Cluster Similarity)       :  0.603446290448172&#34;
[1] &#34;Mean Cluster to Cluster Distance      :  0.61363871360895&#34;
[1] &#34;&#34;
[1] &#34;Run                                   :  9&#34;
[1] &#34;Rand Index (Cluster Similarity)       :  0.979488621012037&#34;
[1] &#34;Mean Cluster to Cluster Distance      :  0.00457590899548947&#34;
[1] &#34;&#34;
[1] &#34;Run                                   :  10&#34;
[1] &#34;Rand Index (Cluster Similarity)       :  0.988407863751361&#34;
[1] &#34;Mean Cluster to Cluster Distance      :  0.00440116014977276&#34;
[1] &#34;&#34;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-r"><pre><span></span>output2<span class="o">&lt;-</span>outputraw<span class="p">[</span><span class="kp">order</span><span class="p">(</span>outputraw<span class="o">$</span>segment<span class="p">),]</span>
output2<span class="o">$</span>segment <span class="o">&lt;-</span> <span class="kp">as.factor</span><span class="p">(</span>output2<span class="o">$</span>segment<span class="p">)</span>
output2<span class="o">$</span>index<span class="o">&lt;-</span><span class="m">1</span><span class="o">:</span><span class="kp">nrow</span><span class="p">(</span>output2<span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now with 9 Segments we see a very different behavior. Our Cluster to Cluster distances are very small and our Rand Indicies are quite large. This is really noticable in the output. Plotting WAGP for each cluster again we see very stable results. Though WAGP for segment 2 and 4 seems to have a tad more error than other segments we only see 'hopping' once in run 8 as opposed to the multiple times we saw it in the clustersize 4 treatment.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-r"><pre><span></span>ggplot<span class="p">(</span>output2<span class="p">,</span> aes<span class="p">(</span>x <span class="o">=</span> index<span class="p">,</span> y <span class="o">=</span> WAGP<span class="p">,</span> colour <span class="o">=</span> segment<span class="p">))</span> <span class="o">+</span> xlab<span class="p">(</span><span class="s">&quot;Cluster Run Index&quot;</span><span class="p">)</span> <span class="o">+</span> 
  geom_point<span class="p">(</span>size <span class="o">=</span> <span class="m">3</span><span class="p">)</span> <span class="o">+</span> ggtitle<span class="p">(</span><span class="s">&quot;Plot of WAGP for Different Cluster in Different Runs&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">


<div class="output_png output_subarea ">
<img src="data:image/png;base64,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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we see from the 4-cluster that picking a small and sensible k from the dendrogram does not yield the same results every time. In fact our 9-cluster result was far more stable (mean 0.94 Rand Index compared to 0.804).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="A-Framework-for-Testing">A Framework for Testing<a class="anchor-link" href="#A-Framework-for-Testing">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So now we've seen failures and successes and more importantly we have a new set of tools at our disposal in order to assess how often we get similarly interpretable results from our method. So what did we originally want?</p>
<p>1) We want our work to be reproducible in the same dataset.</p>
<p>This framework has provided us with several tools that allows us to evaluate the reproducibility of results (most significantly the Rand Index). Over several runs a mean Rand Index of at least 0.8 indicates that the majority of the time (around 70% - 80% depending on your data) there exists an identical interpretation of the clusters, though without at least a 0.9 Rand Index we suggest cautioning that there may be alternative descriptions of the data.</p>
<p>2) We want stronger way to evaluate k.</p>
<p>Fundamentally stability and traditional methods for picking k go hand in hand. While originally we wanted to pick k in order to find a good fit of our model to the dataset, we also want to have reliability. We want to find that 'good' model over and over again. At first we wanted 4 groups and now we see that 9 may lead to far more stable results. And it is not always clear that more or less clusters will be more or less stable. If you run this yourself you'll find that k=5 is pretty unstable as well as k=10.</p>
<p>One could automate this process and grid-search the space for a viable stable numbers of segments. With these results we could narrow our search from all possible k's to a handful of stable ones which fit the data well.</p>
<p>3) We want our segments to be interpretable and actionable.</p>
<p>There's still some 'art' here. Can we effectively action and interpret on 9 separate groups? That depends on the work you plan to do with this data. However, with this approach we now know that a 9 segment approach is stable and while we haven't shown it, others (5 and 10) are not. With this knowledge we can make better calls for the right number of clusters.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Closing-Thoughts">Closing Thoughts<a class="anchor-link" href="#Closing-Thoughts">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div>
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Though this framework gives us a greater confidence over our results, there are still aspects that we feel should be covered in future research. Such as:</p>
<p>1) Extension across different clustering methods (should work across a diverse number of unsupervised methods).</p>
<p>We've found a good deal of value in considering stability in our k-mean clustering method and evaluating the quality of our approach. How much of this work can be extended to other methods? In comparing an idealized version of K-means to results from actual datasets Luxburg 2010 remains convinced that stability can be generally extendable to other algorithms, but they point out 'Whether this principle can be proved to work well for algorithms very different from K-means is an open question.'</p>
<p>2) Initialization.</p>
<p>In our methodology we always led with the belief that out initial segmentation was correct. For stable K's this is mostly likely correct. However, the less stable a K the less likely that we'll correctly guess the most common segmentation the first time. In our 4-cluster scenario we lucked into the right initial segmentation only 70% of the time. In practice we re-run the whole process several times looking for the highest Rand Index (indicating that we lucked into the right initial clustering) and inspecting individual runs for patterns.</p>
<p>There is more than likely a better approach done by not picking an initial segmentation at all and simply storing and comparing the segmentation results. That is perhaps for a future blog post!</p>
<p>3) Stability criterion.</p>
<p>Right now we consider similar mean Rand Indices as a strong metric for Stability, however several metrics are still up for debate in Academic circles including: Rand index, Jaccard index, Hamming distance, minimal matching distance and Variation of Information distance (Meila 2003).</p>
<p>4) Thanks for coming along and good luck picking your K's! I hope to delve into this a bit more with a future blog post and if you have any questions about the method, feel free to contact us!</p>

</div>
</div>
</div>
</div>
</div>
